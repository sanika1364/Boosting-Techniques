{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 1: What is Boosting in Machine Learning? Explain how it improves weak learners.**\n",
        "\n",
        "- Boosting is an ensemble learning technique that sequentially combines multiple weak learners to form a strong learner. The core idea is to train a sequence of models, where each subsequent model focuses on correcting the errors made by the previous ones. Here's how it improves weak learners:\n",
        "\n",
        "**1.Sequential Learning:** Unlike bagging (e.g., Random Forests) where models are trained independently, boosting trains models in a sequence. Each new weak learner is trained with a focus on the examples that the previous learners misclassified or handled poorly.\n",
        "\n",
        "**2.Weighted Data/Errors:** In most boosting algorithms (like AdaBoost), misclassified data points from the previous model are given higher weights or attention in the training of the next model. This forces the subsequent weak learner to concentrate on these 'hard' examples, thereby reducing the overall error.\n",
        "\n",
        "**3.Error Correction:** Each successive weak learner tries to correct the errors of its predecessor. By iteratively refining the model's performance on challenging data points, the ensemble gradually builds a more accurate and robust predictive model.\n",
        "\n",
        "**4.Combining Weaknesses into Strength:** Individually, a weak learner might perform only slightly better than random guessing. However, by combining many such weak learners, each specializing in different aspects of the data or correcting specific errors, boosting creates a powerful model that can achieve high accuracy. The combined predictions often leverage the complementary strengths of the individual weak learners."
      ],
      "metadata": {
        "id": "lMelzsC0AYTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 2: What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?**\n",
        "\n",
        "- The primary difference between AdaBoost and Gradient Boosting lies in how they train subsequent models and address errors:\n",
        "\n",
        "**AdaBoost (Adaptive Boosting):**\n",
        "\n",
        "**- Focus:** AdaBoost adaptively adjusts the weights of the training data instances. It focuses on misclassified samples by increasing their weights in subsequent iterations.\n",
        "\n",
        "**- Error Correction:** Each weak learner tries to correctly classify the weighted data. The overall model learns by giving more importance to previously misclassified data points.\n",
        "\n",
        "**- What new models predict:** Each new weak learner is trained on the original data, but with updated sample weights.\n",
        "\n",
        "**Gradient Boosting:**\n",
        "\n",
        "**- Focus:** Gradient Boosting focuses on fitting subsequent models to the residuals (the errors) of the previous models. It learns from the 'mistakes' by trying to predict what's left to be predicted.\n",
        "\n",
        "**- Error Correction:** Each weak learner is trained to predict the negative gradient of the loss function, which essentially means it's trying to predict the error made by the ensemble so far.\n",
        "\n",
        "**- What new models predict:** Each new weak learner is trained on the residuals (the differences between actual values and the predictions of the previous ensemble), not directly on the original data.\n"
      ],
      "metadata": {
        "id": "0QwRRqvkA71U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 3: How does regularization help in XGBoost?**\n",
        "\n",
        "- Regularization plays a crucial role in XGBoost (Extreme Gradient Boosting) by helping to prevent overfitting and improve the model's generalization capabilities. XGBoost incorporates several types of regularization techniques, primarily driven by its underlying gradient boosting framework:\n",
        "\n",
        "**1. L1 and L2 Regularization (Lasso and Ridge Penalties) on Weights:**\n",
        "\n",
        "  - XGBoost applies L1 (Lasso) and L2 (Ridge) regularization to the weights of the leaf nodes in the trees. These penalties are added to the objective function that XGBoost tries to minimize.\n",
        "\n",
        "  - L1 regularization (alpha parameter): Encourages sparsity by driving some weights to exactly zero, effectively performing feature selection at the tree-building stage and simplifying the model.\n",
        "\n",
        "  - L2 regularization (lambda parameter): Penalizes large weights, discouraging complex models and helping to smooth out the predictions.\n",
        "  \n",
        "  - How it helps: By penalizing the complexity of the individual trees and their leaf weights, these regularizers prevent the model from learning overly specific patterns from the training data that might not generalize well to unseen data. It forces the model to find simpler structures.\n",
        "\n",
        "**2.Shrinkage (Learning Rate / eta parameter):**\n",
        "\n",
        " - XGBoost uses a learning rate (also called eta) that scales down the contribution of each individual tree's prediction when it's added to the ensemble. Instead of adding the full prediction of a new tree, only a fraction of it is added.\n",
        "\n",
        " - How it helps: This technique slows down the learning process, allowing subsequent trees to correct errors more gradually. It prevents any single tree from dominating the learning process and helps to make the overall model more robust. It's like taking small, careful steps towards the optimal solution rather than big, potentially unstable jumps.\n",
        "\n",
        " **3.Subsampling of Rows (subsample parameter):**\n",
        "\n",
        "- XGBoost allows for training each tree on a random fraction of the training data (similar to bagging).\n",
        "\n",
        "- How it helps: This reduces variance by making each tree slightly different and less sensitive to specific training examples. It also speeds up computation for large datasets.\n",
        "\n",
        "**4.Subsampling of Features (colsample_bytree, colsample_bylevel, colsample_bynode parameters):**\n",
        "\n",
        "- XGBoost can also train each tree on a random subset of features (columns).\n",
        "\n",
        "- How it helps: This further reduces variance and prevents any single feature from having too much influence on the model, leading to a more generalized and robust model.\n",
        "\n",
        "**5.Maximum Tree Depth (max_depth parameter):**\n",
        "\n",
        "- While not a regularization technique in the traditional sense of adding a penalty term, limiting the maximum depth of individual trees is a form of pre-pruning that directly controls the complexity of each weak learner.\n",
        "\n",
        "- How it helps: Shallow trees are less likely to overfit. By controlling max_depth, you prevent individual trees from becoming too complex and memorizing the training data.\n",
        "\n",
        "**In summary, regularization in XGBoost:**\n",
        "\n",
        "- Prevents Overfitting: By penalizing complex models and encouraging simpler structures, it ensures the model learns general patterns rather than noise in the training data.\n",
        "\n",
        "- Improves Generalization: A regularized model is more likely to perform well on new, unseen data.\n",
        "\n",
        "- Increases Robustness: Techniques like subsampling reduce the model's sensitivity to individual data points or features.\n",
        "\n",
        "- Provides Control: Hyperparameters like alpha, lambda, eta, subsample, and colsample give users fine-grained control over the bias-variance trade-off."
      ],
      "metadata": {
        "id": "gpsVlyf3Kqut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 4: Why is CatBoost considered efficient for handling categorical data?**\n",
        "\n",
        "CatBoost is considered highly efficient and effective for handling categorical data primarily due to its innovative approach to processing these features, which helps to mitigate common issues like target leakage and prediction shift.\n",
        "\n",
        "Here are the main reasons:\n",
        "\n",
        "**1.Ordered Target Encoding (Permutation-driven Target Encoding):**\n",
        "\n",
        "- The Problem: Traditional target encoding methods (e.g., replacing a category with the average target value for that category) can suffer from target leakage. This happens because the target value itself is used to create the feature, leading to an overly optimistic evaluation of the model's performance on the training data, and poor generalization to new data.\n",
        "\n",
        "- CatBoost's Solution: CatBoost uses a sophisticated, ordered target encoding scheme. For each example in the training set, the categorical feature value is replaced by the average target value of a subset of previous examples (based on a random permutation of the dataset). This means that the target value of the current example is not used in its own feature transformation, thereby preventing target leakage.\n",
        "\n",
        "- Efficiency: This 'ordered' approach ensures that the information used for encoding is always from an 'earlier' point in the data sequence, making the encoding robust and less prone to overfitting.\n",
        "\n",
        "**2.One-Hot Encoding (for low cardinality categories):**\n",
        "\n",
        "- For categorical features with a small number of unique values (low cardinality), CatBoost can automatically apply one-hot encoding. This is a standard and efficient way to handle such features, preventing the creation of too many sparse features that might arise from other encoding methods.\n",
        "\n",
        "**3.Combination of Categorical Features (on-the-fly):**\n",
        "\n",
        "- The Problem: Interactions between categorical features can be very informative, but manually creating all possible combinations can lead to a combinatorial explosion of new features, which is computationally expensive and can lead to overfitting.\n",
        "\n",
        "- CatBoost's Solution: CatBoost can intelligently combine categorical features on-the-fly during training. It doesn't combine all possible pairs or triplets initially; instead, it considers combinations that appear promising (e.g., based on splits in the trees). This allows it to capture complex interactions without the need for extensive manual feature engineering.\n",
        "\n",
        "- Efficiency: By doing this dynamically and only for relevant combinations, it manages complexity and computational cost efficiently.\n",
        "\n",
        "**4.Handling of Missing Values:**\n",
        "\n",
        "- CatBoost has a built-in mechanism to handle missing values in categorical features. It treats missing values as a separate category, allowing the model to learn specific patterns associated with their absence, rather than requiring imputation which can sometimes introduce noise or bias.\n",
        "\n",
        "**5.Prediction Shift Mitigation:**\n",
        "\n",
        "- CatBoost also addresses the problem of prediction shift, which can occur when the distribution of features or target changes between training and testing. By using ordered boosting and its specialized categorical feature handling, it aims to create more stable and generalizable models."
      ],
      "metadata": {
        "id": "lQg0PfG5R---"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 5: What are some real-world applications where boosting techniques are preferred over bagging methods?**\n",
        "\n",
        "Boosting techniques are often preferred over bagging methods (like Random Forests) in real-world applications when the goal is to achieve the highest possible predictive accuracy, particularly in situations where identifying and correcting errors is crucial. While bagging methods reduce variance, boosting methods primarily reduce bias and can often yield superior performance on complex datasets, provided they are carefully tuned to avoid overfitting. Here are some real-world applications where boosting often shines:\n",
        "\n",
        "**1.Fraud Detection:**\n",
        "\n",
        "- Why Boosting? Fraudulent transactions are typically rare events (imbalanced data) and often represent complex patterns that are hard to detect. Boosting algorithms excel at focusing on misclassified instances (potential fraud cases) and sequentially improving their detection ability. Identifying these 'hard-to-learn' cases is critical.\n",
        "\n",
        "- Examples: Detecting credit card fraud, insurance fraud, online transaction anomalies.\n",
        "\n",
        "**2.Credit Risk Assessment:**\n",
        "\n",
        "- Why Boosting? Predicting whether a loan applicant will default is a high-stakes classification problem. Boosting models can learn intricate relationships between various financial indicators and borrower behavior, leading to more accurate predictions of default risk, which directly impacts financial institutions' profitability and stability.\n",
        "\n",
        "- Examples: Approving or denying loan applications, setting interest rates.\n",
        "\n",
        "**3.Medical Diagnosis and Prognosis:**\n",
        "\n",
        "- Why Boosting? In healthcare, accuracy is paramount. Boosting can be used to diagnose diseases based on patient data (symptoms, lab results) or predict disease progression. The iterative error correction nature of boosting helps in building highly accurate models for complex medical scenarios.\n",
        "\n",
        "- Examples: Predicting disease onset (e.g., diabetes, heart disease), cancer recurrence prediction, personalized treatment recommendations.\n",
        "\n",
        "**4.Ad Click-Through Rate (CTR) Prediction / Recommendation Systems:**\n",
        "\n",
        "- Why Boosting? Predicting whether a user will click on an ad or be interested in a product is vital for online advertising and e-commerce. Boosting models can capture subtle user preferences and contextual information to make highly accurate predictions, leading to better ad targeting and product recommendations.\n",
        "\n",
        "- Examples: Personalizing user feeds, suggesting products to buy, optimizing ad placements.\n",
        "\n",
        "**5.Search Ranking:**\n",
        "\n",
        "- Why Boosting? Search engines use complex algorithms to rank web pages based on relevance to a user's query. Boosting algorithms are highly effective in learning from various features (e.g., page content, backlinks, user behavior) to construct sophisticated ranking models that prioritize the most relevant results.\n",
        "\n",
        "- Examples: Google's RankBrain (which is reported to use a form of gradient boosting).\n",
        "\n",
        "**6.Image Recognition and Object Detection (older methods, often combined with feature engineering):**\n",
        "\n",
        "- Why Boosting? Before the deep learning revolution, boosting (especially AdaBoost with Haar features) was a leading technique for object detection (e.g., Viola-Jones face detector). It's efficient at building strong classifiers from simple features by focusing on difficult examples.\n",
        "\n",
        "- Examples: Face detection in digital cameras, pedestrian detection in early autonomous driving systems.\n",
        "\n",
        "**7.Customer Churn Prediction:**\n",
        "\n",
        "- Why Boosting? Identifying customers who are likely to churn (cancel a service) allows companies to proactively intervene. Boosting models can accurately predict churn by learning complex patterns from customer usage data, billing history, and interactions.\n",
        "\n",
        "- Examples: Telecommunications, subscription services, banking.\n",
        "\n",
        "**Key Reasons for Preference:**\n",
        "\n",
        "- Higher Accuracy: Boosting often achieves state-of-the-art results due to its bias-reduction capabilities and ability to correct previous errors.\n",
        "\n",
        "- Focus on Hard Examples: The iterative nature of boosting allows it to pay more attention to misclassified or challenging data points, leading to a more robust model.\n",
        "\n",
        "- Flexibility: Gradient Boosting, in particular, is highly flexible and can optimize various loss functions, making it suitable for a wide range of problem types (classification, regression, ranking, etc.)."
      ],
      "metadata": {
        "id": "QeYnKnAuTc7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Datasets:\n",
        "● Use sklearn.datasets.load_breast_cancer() for classification tasks.\n",
        "\n",
        "● Use sklearn.datasets.fetch_california_housing() for regression\n",
        "tasks.\n"
      ],
      "metadata": {
        "id": "3qk8JDhQW23s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 6: Write a Python program to:**\n",
        "\n",
        "● Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "\n",
        "● Print the model accuracy"
      ],
      "metadata": {
        "id": "xIL7GIfdXPjP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3aef0fc"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c518137"
      },
      "source": [
        "### Load the Breast Cancer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "593af0e7"
      },
      "source": [
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077ecb04"
      },
      "source": [
        "### Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "747013a6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0335f71d"
      },
      "source": [
        "### Train an AdaBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "4eb69b22",
        "outputId": "2d729cf5-d423-4aea-82f2-3f9315189449"
      },
      "source": [
        "# Initialize the base estimator (a decision tree is common for AdaBoost)\n",
        "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "\n",
        "# Initialize AdaBoost Classifier\n",
        "adaboost_model = AdaBoostClassifier(estimator=base_estimator, n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "adaboost_model.fit(X_train, y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   n_estimators=100, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   n_estimators=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>AdaBoostClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
              "                   n_estimators=100, random_state=42)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: DecisionTreeClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=1)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28f8314"
      },
      "source": [
        "### Make predictions and print the model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "513d62c1",
        "outputId": "485aac02-c319-4dea-89f6-8f3babdd7c51"
      },
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = adaboost_model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 7: Write a Python program to:**\n",
        "\n",
        "● Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "\n",
        "● Evaluate performance using R-squared score\n"
      ],
      "metadata": {
        "id": "SwEh19WfYVBS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35667ae2"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9da05294"
      },
      "source": [
        "### Load the California Housing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "849995fb"
      },
      "source": [
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X_housing = housing.data\n",
        "y_housing = housing.target"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52f9309b"
      },
      "source": [
        "### Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dbd904a"
      },
      "source": [
        "X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_housing, y_housing, test_size=0.3, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e469c24"
      },
      "source": [
        "### Train a Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "acabb90b",
        "outputId": "2d51ba25-26c8-4981-ea6c-07e551c4b1da"
      },
      "source": [
        "# Initialize Gradient Boosting Regressor\n",
        "gbr_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "gbr_model.fit(X_train_housing, y_train_housing)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GradientBoostingRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0883fd74"
      },
      "source": [
        "### Make predictions and evaluate performance using R-squared score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5200dd8",
        "outputId": "47c8e286-8009-41d6-ffb4-0eaf9b8ca129"
      },
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_housing = gbr_model.predict(X_test_housing)\n",
        "\n",
        "# Calculate and print the R-squared score\n",
        "r2 = r2_score(y_test_housing, y_pred_housing)\n",
        "print(f\"Gradient Boosting Regressor R-squared: {r2:.4f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor R-squared: 0.7803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 8: Write a Python program to:**\n",
        "\n",
        "● Train an XGBoost Classifier on the Breast Cancer dataset\n",
        "\n",
        "● Tune the learning rate using GridSearchCV\n",
        "\n",
        "● Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "JJpgIhlYYxQC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4db01db2"
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a94df169"
      },
      "source": [
        "### Load the Breast Cancer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f43980b1"
      },
      "source": [
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f9e4908"
      },
      "source": [
        "### Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32e62d60"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1e39a48"
      },
      "source": [
        "### Train an XGBoost Classifier and tune learning rate using GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "c89ad4c1",
        "outputId": "b35de4dd-c15c-4278-b8e6-0df945192b53"
      },
      "source": [
        "# Initialize the XGBoost Classifier\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Define the parameter grid for learning_rate\n",
        "param_grid = {\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:43:41] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None, device=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False,\n",
              "                                     eval_metric='logloss', feature_types=None,\n",
              "                                     feature_weights=None, gamma=None,\n",
              "                                     grow_policy=None, importance_type=None,\n",
              "                                     interaction_constraint...\n",
              "                                     learning_rate=None, max_bin=None,\n",
              "                                     max_cat_threshold=None,\n",
              "                                     max_cat_to_onehot=None,\n",
              "                                     max_delta_step=None, max_depth=None,\n",
              "                                     max_leaves=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     multi_strategy=None, n_estimators=None,\n",
              "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
              "             n_jobs=-1, param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.2]},\n",
              "             scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None, device=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False,\n",
              "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
              "                                     feature_weights=None, gamma=None,\n",
              "                                     grow_policy=None, importance_type=None,\n",
              "                                     interaction_constraint...\n",
              "                                     learning_rate=None, max_bin=None,\n",
              "                                     max_cat_threshold=None,\n",
              "                                     max_cat_to_onehot=None,\n",
              "                                     max_delta_step=None, max_depth=None,\n",
              "                                     max_leaves=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     multi_strategy=None, n_estimators=None,\n",
              "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
              "             n_jobs=-1, param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=XGBClassifier(base_score=None, booster=None,\n",
              "                                     callbacks=None, colsample_bylevel=None,\n",
              "                                     colsample_bynode=None,\n",
              "                                     colsample_bytree=None, device=None,\n",
              "                                     early_stopping_rounds=None,\n",
              "                                     enable_categorical=False,\n",
              "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
              "                                     feature_weights=None, gamma=None,\n",
              "                                     grow_policy=None, importance_type=None,\n",
              "                                     interaction_constraint...\n",
              "                                     learning_rate=None, max_bin=None,\n",
              "                                     max_cat_threshold=None,\n",
              "                                     max_cat_to_onehot=None,\n",
              "                                     max_delta_step=None, max_depth=None,\n",
              "                                     max_leaves=None, min_child_weight=None,\n",
              "                                     missing=nan, monotone_constraints=None,\n",
              "                                     multi_strategy=None, n_estimators=None,\n",
              "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
              "             n_jobs=-1, param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "398a7022"
      },
      "source": [
        "### Print the best parameters and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "647dd966",
        "outputId": "8253af30-0d5a-41b7-aa5f-7e0ea4b47488"
      },
      "source": [
        "# Print the best parameters found by GridSearchCV\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "\n",
        "# Get the best model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "y_pred_xgb = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"XGBoost Classifier Accuracy with best parameters: {accuracy_xgb:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.1}\n",
            "XGBoost Classifier Accuracy with best parameters: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 9: Write a Python program to:**\n",
        "\n",
        "● Train a CatBoost Classifier\n",
        "\n",
        "● Plot the confusion matrix using seaborn"
      ],
      "metadata": {
        "id": "f9bMViXFZOTQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0651a562",
        "outputId": "e35764da-ac55-4acc-d545-50bca03e8e85"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.5)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80cf51d"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2655883a"
      },
      "source": [
        "### Load the Breast Cancer Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afb35455"
      },
      "source": [
        "# Load the breast cancer dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2542892f"
      },
      "source": [
        "### Split the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d80c142"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19d7957d"
      },
      "source": [
        "### Train a CatBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09d74760",
        "outputId": "aa7ca4b7-1ced-4d44-c481-60e8100e5cae"
      },
      "source": [
        "# Initialize CatBoost Classifier\n",
        "cat_model = CatBoostClassifier(iterations=100,  # Number of boosting rounds\n",
        "                                 learning_rate=0.1,\n",
        "                                 depth=6,\n",
        "                                 loss_function='Logloss',\n",
        "                                 eval_metric='Accuracy',\n",
        "                                 random_seed=42,\n",
        "                                 verbose=False) # Set to True for verbose output during training\n",
        "\n",
        "# Train the model\n",
        "cat_model.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f6f32efa150>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eea3d09"
      },
      "source": [
        "### Make predictions and plot the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "ac220ab3",
        "outputId": "11ba69b6-21a8-4a74-a128-6cf4e214004b"
      },
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_cat = cat_model.predict(X_test)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_cat)\n",
        "\n",
        "# Calculate accuracy for reference\n",
        "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
        "print(f\"CatBoost Classifier Accuracy: {accuracy_cat:.4f}\")\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=cancer.target_names,\n",
        "            yticklabels=cancer.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for CatBoost Classifier')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost Classifier Accuracy: 0.9708\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 10: You're working for a FinTech company trying to predict loan default using customer demographics and transaction behavior. The dataset is imbalanced, contains missing values, and has both numeric and categorical features.**\n",
        "\n",
        "Describe your step-by-step data science pipeline using boosting techniques:\n",
        "\n",
        "● Data preprocessing & handling missing/categorical values\n",
        "\n",
        "● Choice between AdaBoost, XGBoost, or CatBoost\n",
        "\n",
        "● Hyperparameter tuning strategy\n",
        "\n",
        "● Evaluation metrics you'd choose and why\n",
        "\n",
        "● How the business would benefit from your model"
      ],
      "metadata": {
        "id": "Pc4gXJcNZ4aM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a836d14"
      },
      "source": [
        "# Task\n",
        "Develop a step-by-step data science pipeline for predicting loan default for a FinTech company, addressing challenges like imbalanced data, missing values, and mixed feature types. The pipeline should include: data preprocessing (handling missing values and encoding categorical features), a justification for choosing between AdaBoost, XGBoost, or CatBoost, a hyperparameter tuning strategy, appropriate evaluation metrics for imbalanced classification, and an explanation of the business benefits of such a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d619416"
      },
      "source": [
        "## Data Preprocessing and Handling Missing/Categorical Values\n",
        "\n",
        "### Subtask:\n",
        "Describe the steps for data preprocessing, including handling missing values (e.g., imputation strategies for numeric and categorical data) and encoding categorical features (e.g., one-hot encoding, target encoding, or CatBoost's native handling).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e458ee1c"
      },
      "source": [
        "## Data Preprocessing and Handling Missing/Categorical Values\n",
        "\n",
        "### Subtask:\n",
        "Describe the steps for data preprocessing, including handling missing values (e.g., imputation strategies for numeric and categorical data) and encoding categorical features (e.g., one-hot encoding, target encoding, or CatBoost's native handling).\n",
        "\n",
        "#### Instructions\n",
        "\n",
        "**1. Handling Missing Values:**\n",
        "\n",
        "*   **For Numerical Features:** Given the sensitive nature of financial data (loan default), a robust imputation strategy is crucial. We would start by analyzing the distribution of each numerical feature with missing values. If the distribution is roughly normal or symmetric, **mean imputation** could be considered. For skewed distributions, **median imputation** would be more appropriate as it is less sensitive to outliers. More advanced techniques like **K-Nearest Neighbors (KNN) imputation** could be explored if there's a strong correlation between features, as KNN imputes values based on the values of the k-nearest samples, providing more accurate estimates. The choice will depend on the percentage of missing values and the potential impact on model performance.\n",
        "\n",
        "*   **For Categorical Features:** Missing values in categorical features can often be very informative. Therefore, the primary approach would be to treat missing values as a **separate category**. This allows the model to learn if the absence of information itself is a predictor of loan default. Alternatively, if the missingness is truly random and the category has a clear dominant value, **mode imputation** could be used. However, creating a 'Missing' category is generally safer and more informative for this type of problem.\n",
        "\n",
        "**2. Encoding Categorical Features:**\n",
        "\n",
        "*   **For Low-Cardinality Categorical Features:** For categorical features with a small, manageable number of unique values (e.g., gender, loan type, marital status), **One-Hot Encoding (OHE)** would be applied. This method creates new binary columns (dummy variables) for each category present in the feature. For example, if 'Gender' has 'Male' and 'Female', it would be converted into two columns, 'Gender_Male' and 'Gender_Female', with 0 or 1 values. This prevents the model from assuming an ordinal relationship between categories.\n",
        "\n",
        "*   **For High-Cardinality Categorical Features:** Features like 'Transaction_ID', 'Customer_ID', or potentially 'City' could have a very large number of unique values. Applying One-Hot Encoding to these would result in an excessive number of new features, leading to the curse of dimensionality, increased memory usage, and potentially model instability. For such features, **Target Encoding** (also known as Mean Encoding or Likelihood Encoding) is an option. This technique replaces each category with the mean of the target variable for that category. For instance, a 'City' might be replaced by the average default rate for loans in that city. However, a significant drawback of basic target encoding is its susceptibility to **target leakage**, where information from the target variable is inadvertently used in the feature creation, leading to an over-optimistic evaluation of the model's performance on the training data. This is particularly problematic in cross-validation.\n",
        "\n",
        "*   **CatBoost's Native Handling:** This is where **CatBoost** becomes a very strong contender for this problem. CatBoost has a sophisticated, built-in mechanism for handling categorical features directly without requiring explicit pre-encoding. It employs an **ordered target encoding** approach. For each observation, the categorical feature value is replaced by the average target value of a subset of *previous* examples (based on a random permutation of the dataset). This intelligent approach ensures that the target value of the current example is *not* used in its own feature transformation, effectively preventing target leakage and mitigating prediction shift. This makes CatBoost exceptionally efficient and robust for datasets with many categorical features, eliminating the need for manual, potentially error-prone, encoding steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c112f43f"
      },
      "source": [
        "## Boosting Model Selection\n",
        "\n",
        "### Subtask:\n",
        "Discuss the considerations for choosing between AdaBoost, XGBoost, and CatBoost, specifically addressing how each algorithm might handle imbalanced data, mixed feature types, and potential advantages/disadvantages in this FinTech context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9d07388"
      },
      "source": [
        "## Boosting Model Selection\n",
        "\n",
        "### Subtask:\n",
        "Discuss the considerations for choosing between AdaBoost, XGBoost, and CatBoost, specifically addressing how each algorithm might handle imbalanced data, mixed feature types, and potential advantages/disadvantages in this FinTech context.\n",
        "\n",
        "### Comparison of Boosting Algorithms for Loan Default Prediction:\n",
        "\n",
        "In the context of predicting loan default, we need to carefully consider how each boosting algorithm (AdaBoost, XGBoost, CatBoost) handles critical aspects such as imbalanced data, mixed feature types, and their overall suitability for a FinTech scenario.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. AdaBoost (Adaptive Boosting)\n",
        "\n",
        "**Characteristics:** AdaBoost works by sequentially training weak learners (typically decision stumps or shallow trees) and adjusting the weights of misclassified training instances in each iteration, forcing subsequent learners to focus on these 'hard' examples.\n",
        "\n",
        "*   **Handling Imbalanced Data:**\n",
        "    *   **Mechanism:** AdaBoost inherently gives more weight to misclassified samples. In an imbalanced dataset, the minority class (e.g., defaulters) is often the one that is harder to classify correctly. By continuously increasing the weights of misclassified minority class samples, AdaBoost naturally focuses more on learning these patterns. This can make it more sensitive to the minority class.\n",
        "    *   **Considerations:** While it focuses on misclassified samples, AdaBoost doesn't directly optimize for metrics like precision or recall that are crucial for imbalanced data. Over-focusing on a very small, noisy minority class might lead to overfitting.\n",
        "\n",
        "*   **Handling Mixed Numeric and Categorical Features:**\n",
        "    *   **Mechanism:** AdaBoost, at its core, relies on the base estimators (e.g., `DecisionTreeClassifier`). These base estimators can handle both numeric and pre-processed categorical features. Numeric features are used directly, while categorical features typically need to be one-hot encoded or label encoded prior to training.\n",
        "    *   **Preprocessing:** Requires explicit preprocessing of categorical features (e.g., One-Hot Encoding for nominal, Label Encoding for ordinal). Missing values also need imputation.\n",
        "\n",
        "*   **Advantages for FinTech Loan Default Prediction:**\n",
        "    *   **Simplicity:** Conceptually simpler than gradient boosting, making it somewhat easier to understand.\n",
        "    *   **Interpretability (Weak Learners):** If using simple base learners like decision stumps, the individual models can be somewhat interpretable, though the ensemble's interpretability decreases with more learners.\n",
        "    *   **Effective with Imbalance:** Its weighting mechanism can naturally give attention to the minority class.\n",
        "\n",
        "*   **Disadvantages for FinTech Loan Default Prediction:**\n",
        "    *   **Sensitivity to Noise/Outliers:** Highly sensitive to noisy data and outliers because it continuously tries to correct previously misclassified points. In financial data, outliers (e.g., extreme transaction behavior) can be common.\n",
        "    *   **Training Speed:** Can be slower than gradient boosting methods with many estimators, as each subsequent model depends heavily on the previous one.\n",
        "    *   **Less Robust:** Generally considered less robust than gradient boosting due to its greedy approach to error correction and lack of explicit regularization.\n",
        "    *   **Limited Optimization:** Less flexible in optimizing different loss functions compared to gradient boosting.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. XGBoost (Extreme Gradient Boosting)\n",
        "\n",
        "**Characteristics:** XGBoost is an optimized distributed gradient boosting library designed for speed and performance. It builds trees sequentially, with each new tree correcting the errors (residuals) of the previous ones. It incorporates regularization techniques to prevent overfitting.\n",
        "\n",
        "*   **Handling Imbalanced Data:**\n",
        "    *   **Mechanism:** XGBoost itself does not have a built-in mechanism that directly prioritizes the minority class through sample weighting like AdaBoost. However, it offers several ways to handle imbalanced data:\n",
        "        *   **`scale_pos_weight`:** This parameter can be set to `(count_negative_samples / count_positive_samples)` to balance the positive and negative weights, effectively giving more importance to the minority class during training.\n",
        "        *   **Custom Objective Function:** Advanced users can define custom objective functions that penalize misclassifications of the minority class more heavily.\n",
        "        *   **Sampling Techniques:** Can be combined with external sampling techniques like SMOTE or undersampling/oversampling.\n",
        "    *   **Considerations:** Explicit configuration via `scale_pos_weight` or careful custom objective/sampling is required for optimal performance on imbalanced datasets.\n",
        "\n",
        "*   **Handling Mixed Numeric and Categorical Features:**\n",
        "    *   **Mechanism:** Like AdaBoost, XGBoost's base learners (CART trees) require categorical features to be pre-processed. It does not natively handle categorical features in its default implementation in the same way CatBoost does.\n",
        "    *   **Preprocessing:** One-hot encoding is the standard approach. For high-cardinality categorical features, this can lead to a very wide dataset, increasing memory usage and potentially training time. Label encoding might be used but can introduce artificial ordinality, which decision trees can sometimes exploit, but it's generally safer with one-hot encoding or target encoding.\n",
        "    *   **Missing Values:** XGBoost can handle missing values internally by learning the optimal direction for splits when a value is missing. This is a significant advantage over models that require explicit imputation.\n",
        "\n",
        "*   **Advantages for FinTech Loan Default Prediction:**\n",
        "    *   **High Performance/Accuracy:** Often achieves state-of-the-art results in tabular data tasks. This is crucial for high-stakes predictions like loan default.\n",
        "    *   **Regularization:** Built-in L1 and L2 regularization (`alpha`, `lambda`) and other techniques (`max_depth`, `subsample`, `colsample_bytree`, `eta`/`learning_rate`) effectively prevent overfitting, which is vital in a domain where generalization to unseen applicants is key.\n",
        "    *   **Speed & Scalability:** Highly optimized, can run on large datasets, and supports parallel processing.\n",
        "    *   **Missing Value Handling:** Native handling of missing values, reducing the need for extensive imputation.\n",
        "    *   **Flexibility:** Supports custom objective functions and evaluation metrics, allowing fine-tuning for specific business needs (e.g., optimizing for minimizing false negatives).\n",
        "\n",
        "*   **Disadvantages for FinTech Loan Default Prediction:**\n",
        "    *   **Parameter Tuning:** Has many hyperparameters, requiring careful tuning to achieve optimal performance and prevent overfitting.\n",
        "    *   **Interpretability:** While it can provide feature importance, understanding the exact interactions of many trees can be challenging, though tools like SHAP values can help.\n",
        "    *   **Categorical Feature Preprocessing:** Requires manual handling of categorical features, which can be cumbersome for datasets with many high-cardinality categories.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. CatBoost (Categorical Boosting)\n",
        "\n",
        "**Characteristics:** CatBoost is another gradient boosting algorithm developed by Yandex, specifically designed to handle categorical features efficiently and robustly. It uses a novel technique for processing categorical features and an ordered boosting scheme to combat prediction shift.\n",
        "\n",
        "*   **Handling Imbalanced Data:**\n",
        "    *   **Mechanism:** CatBoost, similar to XGBoost, doesn't have a direct *sample weighting* mechanism like AdaBoost. However, it provides:\n",
        "        *   **`class_weights`:** Can assign different weights to different classes to address imbalance.\n",
        "        *   **`auto_class_weights`:** Can automatically calculate class weights based on the inverse of class frequencies.\n",
        "        *   **Custom Objective Functions:** Similar to XGBoost, allows for custom loss functions.\n",
        "    *   **Considerations:** Explicitly setting `class_weights` or using `auto_class_weights` is important for imbalanced datasets. Its ordered boosting scheme also makes it inherently more robust, which can indirectly help with minority classes by preventing overfitting caused by prediction shift.\n",
        "\n",
        "*   **Handling Mixed Numeric and Categorical Features:**\n",
        "    *   **Mechanism:** This is CatBoost's standout feature. It handles categorical features *natively* and intelligently:\n",
        "        *   **Ordered Target Encoding:** Instead of traditional target encoding that can cause target leakage, CatBoost uses a sophisticated, permutation-driven approach. For each example, a categorical feature is encoded using the average target value of *only the preceding examples* in a random permutation of the dataset. This prevents target leakage and prediction shift.\n",
        "        *   **On-the-fly Combinations:** It can automatically discover and create combinations of categorical features during training, capturing complex interactions without manual feature engineering.\n",
        "        *   **One-Hot Encoding for Low Cardinality:** For categories with very few unique values, it can automatically apply one-hot encoding.\n",
        "    *   **Preprocessing:** Significantly reduces the need for manual categorical feature preprocessing. Missing values in categorical features are treated as a special category.\n",
        "\n",
        "*   **Advantages for FinTech Loan Default Prediction:**\n",
        "    *   **Superior Categorical Feature Handling:** Its native and robust handling of categorical features is a major advantage, especially in FinTech where demographic data (e.g., occupation, education, marital status) and transaction types are often categorical. This simplifies the pipeline and reduces the risk of leakage or suboptimal encoding.\n",
        "    *   **Robustness to Overfitting:** The ordered boosting principle and special handling of categorical features make it highly robust to overfitting, leading to better generalization.\n",
        "    *   **Less Parameter Tuning:** Generally requires less hyperparameter tuning than XGBoost to achieve good results.\n",
        "    *   **Good Default Parameters:** Often performs well with default parameters.\n",
        "    *   **Built-in Missing Value Handling:** Handles missing values naturally.\n",
        "\n",
        "*   **Disadvantages for FinTech Loan Default Prediction:**\n",
        "    *   **Training Speed (Categorical Encoding):** The ordered target encoding and on-the-fly combinations can sometimes make training slower than XGBoost, especially with a very high number of high-cardinality categorical features.\n",
        "    *   **Interpretability:** Similar to XGBoost, understanding the complex interactions of many trees is difficult.\n",
        "    *   **Memory Usage:** Can be more memory-intensive due to its encoding mechanisms.\n",
        "\n",
        "---\n",
        "\n",
        "### Recommendation for Loan Default Prediction:\n",
        "\n",
        "For a FinTech company predicting loan default with an imbalanced dataset containing missing values and mixed numeric/categorical features, **CatBoost** or **XGBoost** would be the most suitable choices, with a slight edge to **CatBoost** given the strong emphasis on categorical data handling in FinTech.\n",
        "\n",
        "**Justification:**\n",
        "\n",
        "1.  **Handling Imbalanced Data:** Both XGBoost and CatBoost provide mechanisms (`scale_pos_weight` / `class_weights`) to address data imbalance directly in their objective functions, which is more principled than AdaBoost's implicit weighting. This allows us to explicitly optimize for metrics like recall (identifying defaulters) or F1-score.\n",
        "\n",
        "2.  **Handling Mixed Feature Types:** This is where CatBoost truly shines. Given that customer demographics and transaction behavior often involve numerous categorical features, CatBoost's native, leakage-free handling of these features significantly simplifies the preprocessing pipeline and typically leads to more robust models. XGBoost would require extensive manual preprocessing (e.g., one-hot encoding or careful target encoding) for categorical features, which can be error-prone and computationally expensive for high-cardinality features.\n",
        "\n",
        "3.  **Regularization and Robustness:** Both XGBoost and CatBoost are highly robust and incorporate strong regularization techniques that are crucial for preventing overfitting in a sensitive domain like FinTech. AdaBoost's sensitivity to noisy data and lack of explicit regularization make it a less ideal choice for this high-stakes scenario.\n",
        "\n",
        "4.  **Performance:** Both XGBoost and CatBoost are known for achieving high predictive accuracy, which is paramount in loan default prediction to minimize financial risk.\n",
        "\n",
        "5.  **Interpretability (Post-hoc):** While none of these are inherently as interpretable as a single decision tree, tools like SHAP values can be applied to both XGBoost and CatBoost to gain insights into feature importance and individual prediction explanations, which is valuable for compliance and business understanding in FinTech.\n",
        "\n",
        "**Why CatBoost might be preferred:** Its built-in, intelligent handling of categorical features (ordered target encoding and on-the-fly combinations) is a significant advantage, as it automates a complex and often critical part of the feature engineering process, reduces the risk of data leakage, and inherently addresses prediction shift. This makes the overall pipeline simpler, more robust, and less prone to manual errors, leading to potentially better-generalizing models with less effort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21e3a150"
      },
      "source": [
        "## Hyperparameter Tuning Strategy\n",
        "\n",
        "### Subtask:\n",
        "Explain a strategy for hyperparameter tuning, including methods like GridSearchCV or RandomizedSearchCV, the importance of cross-validation, and specific hyperparameters relevant to the chosen boosting model for imbalanced datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "392ee5e6"
      },
      "source": [
        "### Hyperparameter Tuning Strategy\n",
        "\n",
        "For predicting loan default, a robust hyperparameter tuning strategy is crucial to optimize model performance, especially given the dataset's characteristics (imbalanced, mixed feature types). Here's a step-by-step approach:\n",
        "\n",
        "**1. Methods for Tuning: GridSearchCV vs. RandomizedSearchCV**\n",
        "\n",
        "-   **GridSearchCV:** This method performs an exhaustive search over a specified parameter grid. It tries every possible combination of hyperparameters provided. For our problem:\n",
        "    -   **Advantages:** Guarantees finding the best combination within the defined search space. Useful for smaller, well-understood search spaces.\n",
        "    -   **Disadvantages:** Computationally expensive and time-consuming, especially with many hyperparameters or a large search space. With a complex boosting model and a potentially wide range of optimal values, it might be impractical for initial, broad searches.\n",
        "\n",
        "-   **RandomizedSearchCV:** This method samples a fixed number of parameter settings from specified distributions. It explores random combinations of hyperparameters from a given search space. For our problem:\n",
        "    -   **Advantages:** More computationally efficient than `GridSearchCV`, allowing for exploration of a larger search space in less time. Often finds a good set of hyperparameters faster, particularly when many parameters don't significantly impact performance.\n",
        "    -   **Disadvantages:** Does not guarantee finding the absolute best combination, as it doesn't explore all possibilities. However, for complex models with many hyperparameters, it's often more effective at finding good regions of the search space.\n",
        "\n",
        "**Recommendation:** For the initial broad search, `RandomizedSearchCV` is generally preferred due to its computational efficiency. Once a promising region in the hyperparameter space is identified, `GridSearchCV` can be used for a finer-grained search within that region.\n",
        "\n",
        "**2. Importance of Cross-Validation**\n",
        "\n",
        "Cross-validation is absolutely crucial for reliable model evaluation and preventing overfitting during hyperparameter tuning. It provides a more robust estimate of how the model will generalize to unseen data compared to a single train-test split.\n",
        "\n",
        "-   **Mechanism:** The dataset is split into `k` folds. The model is trained `k` times, each time using `k-1` folds for training and the remaining fold for validation. The performance metrics are then averaged across all `k` runs.\n",
        "-   **Preventing Overfitting:** By evaluating the model on multiple independent validation sets, cross-validation helps detect if the model is memorizing the training data rather than learning generalizable patterns.\n",
        "-   **Reliable Evaluation:** It provides a more stable estimate of the model's performance and parameter sensitivity, reducing the impact of a particular split of the data.\n",
        "-   **Importance for Imbalanced Data (Loan Default):** Given the imbalanced nature of loan default data (few defaults, many non-defaults), **Stratified K-Fold Cross-Validation** is essential. This technique ensures that each fold maintains the same class distribution as the original dataset, preventing a fold from having too few (or no) default cases, which would lead to biased evaluation.\n",
        "\n",
        "**3. Relevant Hyperparameters for Boosting Models (XGBoost/CatBoost)**\n",
        "\n",
        "Assuming we are using CatBoost or XGBoost for their strengths with mixed data types and performance:\n",
        "\n",
        "-   **General Hyperparameters (Complexity Control & Learning):**\n",
        "    -   `n_estimators` (or `iterations` for CatBoost): The number of boosting rounds (trees). More trees increase model complexity and training time; needs to be balanced with learning rate.\n",
        "    -   `learning_rate` (or `eta` for XGBoost): Shrinks the contribution of each tree. A smaller learning rate usually requires more `n_estimators` but leads to more robust models and helps prevent overfitting.\n",
        "    -   `max_depth`: The maximum depth of each individual tree. Controls the complexity of individual weak learners. Deeper trees can capture more complex interactions but are more prone to overfitting.\n",
        "    -   `subsample`: The fraction of samples used for fitting the base learners. Reduces variance and helps prevent overfitting (similar to bagging).\n",
        "    -   `colsample_bytree` (or `colsample_bylevel`, `colsample_bynode` for XGBoost): The fraction of features (columns) to consider when building each tree. Reduces variance and prevents reliance on specific features.\n",
        "    -   `min_child_weight` (XGBoost) / `min_data_in_leaf` (CatBoost): Minimum sum of instance weight (Hessian) needed in a child. Controls tree pruning and prevents individual trees from becoming too complex.\n",
        "    -   `gamma` (XGBoost) / `l1_leaf_reg`, `l2_leaf_reg` (CatBoost): Regularization parameters. `gamma` (min_split_loss) for XGBoost specifies the minimum loss reduction required to make a further partition on a leaf node. CatBoost's `l1_leaf_reg` and `l2_leaf_reg` are L1/L2 regularization terms on leaf values.\n",
        "\n",
        "-   **Hyperparameters for Handling Class Imbalance:**\n",
        "    -   `scale_pos_weight` (XGBoost): This is a crucial parameter for imbalanced datasets. It controls the balance of positive and negative weights, useful for unbalanced classes. A common value is `count(negative_examples) / count(positive_examples)`. It essentially gives more weight to the minority class (loan defaults).\n",
        "    -   `auto_class_weights` (CatBoost): CatBoost can automatically calculate and apply class weights based on the dataset's class distribution. This is a convenient feature for handling imbalance.\n",
        "    -   `class_weights` (CatBoost): Manually define weights for each class, giving higher weight to the minority class. This can be fine-tuned based on domain knowledge or experimental results.\n",
        "\n",
        "**4. Imbalance-Specific Tuning Considerations**\n",
        "\n",
        "When tuning for imbalanced datasets, simply maximizing accuracy can be misleading, as a model might achieve high accuracy by classifying everything as the majority class. Therefore, the choice of evaluation metric during tuning (`scoring` parameter in `GridSearchCV`/`RandomizedSearchCV`) is paramount.\n",
        "\n",
        "-   **Focus on Recall, Precision, F1-Score, or AUC-ROC/PR:** For loan default prediction, we are likely more interested in correctly identifying actual defaults (high recall for the positive class) while minimizing false positives (high precision for the positive class), or a balance of both. AUC-ROC (Area Under the Receiver Operating Characteristic curve) or AUC-PR (Area Under the Precision-Recall curve) are robust metrics for imbalanced classification. AUC-PR is often preferred when the positive class is very rare.\n",
        "-   **Direct Tuning of Imbalance Parameters:** `scale_pos_weight` (XGBoost) or `class_weights` (CatBoost) should be included in the hyperparameter search space. We might start with the default (or calculated) imbalance ratio and then fine-tune it around that value.\n",
        "\n",
        "**5. Iterative Tuning Approach**\n",
        "\n",
        "An iterative approach to tuning is generally most effective:\n",
        "\n",
        "1.  **Broad Search (RandomizedSearchCV):** Start with `RandomizedSearchCV` across a wide range for key parameters like `n_estimators`, `learning_rate`, `max_depth`, `subsample`, `colsample_bytree`, and imbalance-handling parameters (e.g., `scale_pos_weight`). Use `Stratified K-Fold` for cross-validation and an appropriate `scoring` metric (e.g., 'roc_auc' or 'f1').\n",
        "2.  **Refined Search (GridSearchCV/RandomizedSearchCV):** Based on the results of the broad search, identify narrower, more promising ranges for the best-performing hyperparameters. Then, use `GridSearchCV` or another round of `RandomizedSearchCV` with finer steps within these refined ranges.\n",
        "3.  **Focus on Regularization:** Introduce or further tune regularization parameters (`gamma`, `min_child_weight`, `l1_leaf_reg`, `l2_leaf_reg`) to control overfitting if still observed.\n",
        "4.  **Sequential Tuning (Optional but Recommended):** Sometimes, tuning parameters in groups (e.g., first `n_estimators` and `learning_rate`, then tree-specific parameters like `max_depth`, then regularization, and finally imbalance parameters) can be more efficient, especially if computational resources are limited. This is often done by keeping other parameters at reasonable defaults while tuning a specific group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c6c59b2"
      },
      "source": [
        "## Evaluation Metrics and Justification\n",
        "\n",
        "### Subtask:\n",
        "Identify and justify appropriate evaluation metrics for an imbalanced classification problem like loan default prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3460953f"
      },
      "source": [
        "### 1. Why Standard Accuracy is Insufficient for Imbalanced Datasets (Loan Default Prediction)\n",
        "\n",
        "In the context of loan default prediction, the dataset is inherently imbalanced. The vast majority of borrowers will repay their loans (negative class), while a much smaller percentage will default (positive class). Standard accuracy, which is calculated as the ratio of correctly predicted instances to the total instances, can be highly misleading in such scenarios.\n",
        "\n",
        "**Example:**\n",
        "Consider a dataset where only 5% of loans default (positive class) and 95% are repaid (negative class). A very simple model that *always predicts 'no default'* would achieve an accuracy of 95%. While this number seems high, the model is completely useless for the business purpose of identifying potential defaulters, as it fails to identify *any* of the actual defaults. It has a 0% recall for the positive class.\n",
        "\n",
        "**Why it's insufficient for loan default prediction:**\n",
        "\n",
        "*   **Misleading Performance:** A high accuracy score can give a false sense of security, making it seem like the model is performing well, even if it's completely failing to detect the minority (defaulting) class. For a FinTech company, missing actual defaulters can lead to significant financial losses.\n",
        "*   **Ignores Minority Class Performance:** Accuracy doesn't distinguish between correctly predicting the majority class and correctly predicting the minority class. In loan default prediction, identifying the minority class (defaulters) is often the primary goal, as these are the high-risk cases that need attention.\n",
        "*   **Business Impact:** The business cost of misclassifying a defaulter as a non-defaulter (False Negative) is typically much higher than misclassifying a non-defaulter as a defaulter (False Positive). Accuracy treats all errors equally, which is not aligned with the real-world business implications of loan default prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66d404e5"
      },
      "source": [
        "### 2. Key Evaluation Metrics for Imbalanced Classification (Loan Default Prediction)\n",
        "\n",
        "Given the limitations of accuracy for imbalanced datasets, several other metrics are more appropriate for evaluating models, especially in high-stakes scenarios like loan default prediction. These metrics provide a more nuanced understanding of a model's performance, particularly regarding the minority class.\n",
        "\n",
        "Here's a breakdown of key metrics:\n",
        "\n",
        "#### a. Confusion Matrix\n",
        "\n",
        "Before diving into specific metrics, it's crucial to understand the **Confusion Matrix**, which forms the basis for many classification performance measures. For binary classification (like default/no default), it's a 2x2 table:\n",
        "\n",
        "|                   | **Predicted: No Default** | **Predicted: Default** |\n",
        "| :---------------- | :------------------------ | :--------------------- |\n",
        "| **Actual: No Default** | True Negative (TN)        | False Positive (FP)    |\n",
        "| **Actual: Default**    | False Negative (FN)       | True Positive (TP)     |\n",
        "\n",
        "*   **True Positive (TP):** Correctly predicted actual defaulters.\n",
        "*   **True Negative (TN):** Correctly predicted actual non-defaulters.\n",
        "*   **False Positive (FP):** Incorrectly predicted a non-defaulter as a defaulter (Type I error).\n",
        "*   **False Negative (FN):** Incorrectly predicted a defaulter as a non-defaulter (Type II error).\n",
        "\n",
        "**Relevance for Loan Default:**\n",
        "*   **FP (Type I Error):** A healthy borrower is incorrectly flagged as a potential defaulter. Business impact: The FinTech company might deny a loan to a creditworthy customer, losing potential revenue and potentially customer goodwill. This is generally less costly than an FN.\n",
        "*   **FN (Type II Error):** A borrower who will default is incorrectly flagged as a non-defaulter. Business impact: The FinTech company approves a loan to a borrower who will default, leading to financial loss from the defaulted loan. This is often the more critical and costly error in this domain.\n",
        "\n",
        "#### b. Precision (Positive Predictive Value)\n",
        "\n",
        "Precision measures the proportion of positive identifications that were actually correct. It answers: \"Of all the instances the model predicted as positive, how many were truly positive?\"\n",
        "\n",
        "**Formula:** `Precision = TP / (TP + FP)`\n",
        "\n",
        "**Relevance for Loan Default:**\n",
        "High precision means fewer False Positives. If a FinTech company wants to minimize incorrectly rejecting creditworthy applicants (and thus maximize efficiency of their sales/operations team by only reviewing highly likely defaulters), precision is important. However, focusing solely on precision might lead to missing many actual defaulters (high FN rate) if the model is too conservative.\n",
        "\n",
        "#### c. Recall (Sensitivity, True Positive Rate)\n",
        "\n",
        "Recall measures the proportion of actual positives that were correctly identified. It answers: \"Of all the actual positive instances, how many did the model correctly identify?\"\n",
        "\n",
        "**Formula:** `Recall = TP / (TP + FN)`\n",
        "\n",
        "**Relevance for Loan Default:**\n",
        "High recall means fewer False Negatives. In loan default prediction, **recall for the 'default' class is often paramount**. The FinTech company's primary goal is to identify as many potential defaulters as possible to mitigate financial risk. A model with low recall means many risky loans are approved, leading to significant losses. This metric is crucial because of the high cost associated with False Negatives.\n",
        "\n",
        "#### d. F1-Score\n",
        "\n",
        "The F1-score is the harmonic mean of Precision and Recall. It provides a single score that balances both precision and recall. It's particularly useful when you need to seek a balance between FP and FN, and when there is an uneven class distribution.\n",
        "\n",
        "**Formula:** `F1-Score = 2 * (Precision * Recall) / (Precision + Recall)`\n",
        "\n",
        "**Relevance for Loan Default:**\n",
        "The F1-score offers a good overall measure when both minimizing False Positives (efficient processing) and False Negatives (risk mitigation) are important, but you want a single metric to optimize. It helps to find a sweet spot where the model is not too conservative (missing defaulters) nor too aggressive (rejecting too many good applicants).\n",
        "\n",
        "#### e. ROC AUC (Receiver Operating Characteristic - Area Under the Curve)\n",
        "\n",
        "The ROC curve plots the True Positive Rate (Recall) against the False Positive Rate (`FP / (FP + TN)`) at various classification thresholds. The AUC (Area Under the Curve) measures the entire area underneath the ROC curve. A higher AUC indicates a better ability of the model to distinguish between positive and negative classes.\n",
        "\n",
        "**Relevance for Loan Default:**\n",
        "ROC AUC is valuable because it provides an aggregate measure of performance across all possible classification thresholds. It's less sensitive to class imbalance than accuracy. A high ROC AUC indicates that the model can effectively rank potential defaulters higher than non-defaulters. This is useful for decision-making, as the FinTech company can choose a threshold that balances risk tolerance and customer acquisition goals.\n",
        "\n",
        "#### f. Precision-Recall AUC (PR AUC)\n",
        "\n",
        "The Precision-Recall curve plots Precision against Recall at various classification thresholds. The Area Under the Precision-Recall Curve is particularly useful for highly imbalanced datasets, where the positive class is rare. For such datasets, PR AUC often provides a more informative and optimistic view of performance than ROC AUC, especially when the goal is to detect the minority class.\n",
        "\n",
        "**Relevance for Loan Default:**\n",
        "Given that loan default is typically a rare event, **PR AUC is often considered one of the most appropriate metrics**. It directly focuses on the performance of the positive class (defaulters). A high PR AUC means the model performs well in identifying defaulters without generating an excessive number of false alarms. It is more sensitive to changes in the number of positive predictions compared to ROC AUC, making it a better indicator of how well the model identifies the minority class when it truly matters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af40293a"
      },
      "source": [
        "### 3. Most Critical Metrics for a FinTech Company Predicting Loan Default\n",
        "\n",
        "For a FinTech company predicting loan default, the choice of the most critical evaluation metrics hinges on a careful consideration of the business objectives and the differing costs associated with False Positives (FP) and False Negatives (FN).\n",
        "\n",
        "In the context of loan default:\n",
        "\n",
        "*   **False Negative (FN):** A customer who will default is predicted as non-defaulting. **Business Implication:** This is typically the *most costly error*. The company approves a loan that will not be repaid, leading to direct financial loss (principal + interest) and administrative costs for collection efforts. This directly impacts the company's profitability and risk exposure.\n",
        "\n",
        "*   **False Positive (FP):** A customer who will not default is predicted as defaulting. **Business Implication:** The company denies a loan to a creditworthy customer. This leads to *opportunity cost* (lost potential revenue from interest) and potentially damages customer relations. While undesirable, the financial impact of a single FP is generally less severe than a single FN.\n",
        "\n",
        "Given this imbalance in error costs, the FinTech company would prioritize metrics that effectively minimize False Negatives, while still keeping False Positives at an acceptable level.\n",
        "\n",
        "Therefore, the most critical metrics would be:\n",
        "\n",
        "1.  **Recall (for the 'default' class):**\n",
        "    *   **Why it's critical:** The primary objective of a loan default prediction model is to identify as many actual defaulters as possible to prevent financial losses. High recall ensures that a large proportion of actual defaulting loans are flagged, allowing the company to mitigate risk by either denying the loan or offering it with adjusted terms. Maximizing recall directly addresses the goal of minimizing the most costly error (FN).\n",
        "\n",
        "2.  **Precision-Recall AUC (PR AUC):**\n",
        "    *   **Why it's critical:** As discussed, loan default is an inherently imbalanced problem. PR AUC provides a robust and informative aggregate measure of a model's ability to identify the positive (defaulting) class without being overly sensitive to the majority class. It directly reflects the trade-off between identifying defaulters (recall) and avoiding misclassifying non-defaulters as defaulters (precision). A high PR AUC indicates a model that performs well in detecting the rare, critical event of default while maintaining reasonable precision across various thresholds. This is often a better overall indicator for highly imbalanced datasets than ROC AUC.\n",
        "\n",
        "3.  **F1-Score:**\n",
        "    *   **Why it's critical:** While Recall is often prioritized, an extremely high recall achieved at the cost of very low precision (i.e., flagging almost everyone as a potential defaulter) would make the model impractical due to excessive FPs. The F1-score provides a single metric that balances both precision and recall. It's useful for finding a threshold that ensures sufficient recall while maintaining an acceptable level of precision, thereby making the model's recommendations actionable for the business without causing too many unnecessary rejections.\n",
        "\n",
        "**ROC AUC** is also valuable for understanding the model's overall discriminative power across all thresholds and is less sensitive to class imbalance than accuracy. However, for heavily imbalanced datasets where the positive class is the main focus, PR AUC often provides a more direct and insightful measure of performance in the region of interest (high recall for the positive class).\n",
        "\n",
        "**In summary, for a FinTech company, the model's performance on the minority class (defaulters) is paramount. Metrics like Recall, PR AUC, and F1-Score are essential for ensuring the model effectively minimizes financial losses due to loan defaults, while also considering the efficiency and customer experience implications of False Positives.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec5c3d3e"
      },
      "source": [
        "### 3. Most Critical Metrics for a FinTech Company Predicting Loan Default\n",
        "\n",
        "For a FinTech company predicting loan default, the choice of the most critical evaluation metrics hinges on a careful consideration of the business objectives and the differing costs associated with False Positives (FP) and False Negatives (FN).\n",
        "\n",
        "In the context of loan default:\n",
        "\n",
        "*   **False Negative (FN):** A customer who will default is predicted as non-defaulting. **Business Implication:** This is typically the *most costly error*. The company approves a loan that will not be repaid, leading to direct financial loss (principal + interest) and administrative costs for collection efforts. This directly impacts the company's profitability and risk exposure.\n",
        "\n",
        "*   **False Positive (FP):** A customer who will not default is predicted as defaulting. **Business Implication:** The company denies a loan to a creditworthy customer. This leads to *opportunity cost* (lost potential revenue from interest) and potentially damages customer relations. While undesirable, the financial impact of a single FP is generally less severe than a single FN.\n",
        "\n",
        "Given this imbalance in error costs, the FinTech company would prioritize metrics that effectively minimize False Negatives, while still keeping False Positives at an acceptable level.\n",
        "\n",
        "Therefore, the most critical metrics would be:\n",
        "\n",
        "1.  **Recall (for the 'default' class):**\n",
        "    *   **Why it's critical:** The primary objective of a loan default prediction model is to identify as many actual defaulters as possible to prevent financial losses. High recall ensures that a large proportion of actual defaulting loans are flagged, allowing the company to mitigate risk by either denying the loan or offering it with adjusted terms. Maximizing recall directly addresses the goal of minimizing the most costly error (FN).\n",
        "\n",
        "2.  **Precision-Recall AUC (PR AUC):**\n",
        "    *   **Why it's critical:** As discussed, loan default is an inherently imbalanced problem. PR AUC provides a robust and informative aggregate measure of a model's ability to identify the positive (defaulting) class without being overly sensitive to the majority class. It directly reflects the trade-off between identifying defaulters (recall) and avoiding misclassifying non-defaulters as defaulters (precision). A high PR AUC indicates a model that performs well in detecting the rare, critical event of default while maintaining reasonable precision across various thresholds. This is often a better overall indicator for highly imbalanced datasets than ROC AUC.\n",
        "\n",
        "3.  **F1-Score:**\n",
        "    *   **Why it's critical:** While Recall is often prioritized, an extremely high recall achieved at the cost of very low precision (i.e., flagging almost everyone as a potential defaulter) would make the model impractical due to excessive FPs. The F1-score provides a single metric that balances both precision and recall. It's useful for finding a threshold that ensures sufficient recall while maintaining an acceptable level of precision, thereby making the model's recommendations actionable for the business without causing too many unnecessary rejections.\n",
        "\n",
        "**ROC AUC** is also valuable for understanding the model's overall discriminative power across all thresholds and is less sensitive to class imbalance than accuracy. However, for heavily imbalanced datasets where the positive class is the main focus, PR AUC often provides a more direct and insightful measure of performance in the region of interest (high recall for the positive class).\n",
        "\n",
        "**In summary, for a FinTech company, the model's performance on the minority class (defaulters) is paramount. Metrics like Recall, PR AUC, and F1-Score are essential for ensuring the model effectively minimizes financial losses due to loan defaults, while also considering the efficiency and customer experience implications of False Positives.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2809eec5"
      },
      "source": [
        "## Business Impact and Benefits\n",
        "\n",
        "### Subtask:\n",
        "Detail how a robust loan default prediction model would benefit a FinTech company.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15b7135a"
      },
      "source": [
        "A robust loan default prediction model offers significant benefits to a FinTech company, directly impacting its profitability, risk management, and strategic decision-making:\n",
        "\n",
        "**1. Risk Mitigation and Reduced Financial Losses:**\n",
        "   - **Proactive Identification:** The primary benefit is the ability to identify potential defaulters *before* loans are disbursed. This allows the company to decline high-risk applications, adjust loan terms, or offer alternative products.\n",
        "   - **Lower Write-Offs:** By minimizing loans given to individuals likely to default, the company significantly reduces the amount of unrecoverable debt, leading to fewer financial write-offs.\n",
        "   - **Capital Preservation:** Reduced defaults mean the company retains more capital, which can then be re-invested or used for other growth initiatives.\n",
        "\n",
        "**2. Optimized Lending Decisions:**\n",
        "   - **Accurate Credit Scoring:** The model provides a more nuanced and accurate assessment of an applicant's creditworthiness beyond traditional credit scores, incorporating a wider range of demographic and behavioral data.\n",
        "   - **Tailored Loan Products:** With a better understanding of risk profiles, the FinTech can design and offer highly tailored loan products, interest rates, and repayment schedules that match individual borrower capabilities, increasing acceptance rates for viable customers while deterring high-risk ones.\n",
        "   - **Automated Decision-Making:** A robust model can automate much of the loan approval process, leading to faster decisions, improved customer experience, and reduced operational costs.\n",
        "\n",
        "**3. Improved Customer Segmentation and Personalized Offerings:**\n",
        "   - **Granular Segmentation:** The insights from the model can help segment customers not just by default risk, but also by their propensity to repay on time, their financial stability, and their needs. This allows for more precise marketing and product development.\n",
        "   - **Personalized Recommendations:** Beyond just loan approval, the model can inform personalized financial advice, cross-selling other suitable financial products, or even recommending financial literacy resources to customers at different risk levels.\n",
        "   - **Customer Lifetime Value (CLV):** By identifying and retaining good customers and offering them appropriate products, the company can maximize their Customer Lifetime Value.\n",
        "\n",
        "**4. Regulatory Compliance and Ethical Lending:**\n",
        "   - **Fairness and Transparency:** A well-built model, especially with careful feature engineering and interpretability, can help ensure fair lending practices and reduce bias, which is crucial for regulatory compliance and maintaining public trust.\n",
        "   - **Stress Testing:** The model can be used to simulate various economic scenarios and assess the portfolio's resilience, aiding in risk management and capital planning in line with regulatory requirements.\n",
        "\n",
        "**5. Competitive Advantage:**\n",
        "   - **Speed and Efficiency:** Faster and more accurate lending decisions provide a significant competitive edge in the fast-paced FinTech industry.\n",
        "   - **Innovation:** The insights gained from the model can drive further innovation in product development, customer engagement strategies, and overall business model optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b129618"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the step-by-step data science pipeline for loan default prediction using boosting techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34bc3fc5"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Data Preprocessing Strategies:** For missing numerical features, mean/median imputation (depending on distribution) or K-Nearest Neighbors (KNN) imputation were recommended. Missing categorical values are best treated as a separate category. One-Hot Encoding is suitable for low-cardinality categorical features, while CatBoost's native, leakage-free ordered target encoding is highly preferred for high-cardinality features, simplifying the pipeline and enhancing robustness.\n",
        "*   **Boosting Model Selection:** XGBoost and CatBoost were identified as the most suitable models for loan default prediction due to their performance, regularization capabilities, and handling of imbalanced data. CatBoost was given a slight edge for its superior and native handling of categorical features (using ordered target encoding), which is particularly beneficial in FinTech datasets rich in such features, preventing target leakage and reducing manual preprocessing effort.\n",
        "*   **Hyperparameter Tuning Strategy:** `RandomizedSearchCV` was recommended for initial broad searches, followed by `GridSearchCV` for refined tuning. **Stratified K-Fold Cross-Validation** was emphasized as crucial for robust evaluation, especially for imbalanced datasets, ensuring representative class distribution across folds. Key hyperparameters to tune include `n_estimators`, `learning_rate`, `max_depth`, regularization terms, and imbalance-specific parameters like `scale_pos_weight` (XGBoost) or `class_weights` (CatBoost).\n",
        "*   **Evaluation Metrics for Imbalanced Data:** Standard accuracy was deemed insufficient and misleading for loan default prediction due to the severe class imbalance. **Recall (for the 'default' class)**, **Precision-Recall AUC (PR AUC)**, and **F1-Score** were identified as the most critical evaluation metrics. This is because **False Negatives (missing a defaulter)** are typically far more costly errors for a FinTech company (direct financial loss) than False Positives (denying a creditworthy applicant, an opportunity cost). PR AUC specifically provides a more informative and robust measure of performance for rare positive classes compared to ROC AUC.\n",
        "*   **Business Benefits:** A robust loan default prediction model offers significant benefits, including **risk mitigation** (proactive identification of defaulters, reduced write-offs, capital preservation), **optimized lending decisions** (accurate credit scoring, tailored loan products, automated processes), **improved customer segmentation**, and ensuring **regulatory compliance** through fairer and more transparent lending practices. It provides a crucial competitive advantage through speed, efficiency, and data-driven innovation.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Prioritize CatBoost for model development due to its integrated and robust handling of categorical features, which significantly simplifies preprocessing and reduces the risk of data leakage, often leading to more generalizable models in FinTech contexts.\n",
        "*   When optimizing the model, focus hyperparameter tuning efforts and model evaluation primarily on metrics that reflect the business cost of errors, such as maximizing **Recall** for the default class and achieving a high **Precision-Recall AUC**, to effectively minimize financial losses from undetected loan defaults.\n"
      ]
    }
  ]
}